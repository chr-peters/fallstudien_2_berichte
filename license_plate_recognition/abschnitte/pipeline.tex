\section{Pipeline}
\label{sec:pipeline}

Eine schematische \"Ubersicht der in diesem Projekt eingesetzten
zweistufigen Vorhersagepipeline ist in Abbildung~\ref{fig:pipeline}
dargestellt.

Die Pipeline ist so aufgebaut, dass auf eine Bildeingabe zun\"achst
eine Bildsegmentierung angewendet wird, um den Bereich des Bildes,
welcher das Nummernschild enth\"alt, herauszutrennen.
F\"ur die Bildsegmentierung wurde ein neuronales Netz trainiert,
die Einzelheiten des Verfahrens werden in Abschnitt~\ref{sec:bildsegmentierung}
n\"aher beschrieben.

Nach der Bildsegmentierung wird auf den herausgetrennten Bereich eine
Texterkennung angewendet, um die Zeichenfolge des Nummernschildes
zu extrahieren. Dieses Verfahren wird in Abschnitt~\ref{sec:texterkennung}
beschrieben.

\begin{figure}
    \centering
    \includegraphics[width=\textwidth]{abbildungen/pipeline}
    \caption{Schematische Darstellung der zweistufigen Vorhersagepipeline.
        Zun\"achst wird das Nummernschild mithilfe von Bildsegmentierung
        extrahiert. Anschlie{\ss}end werden die Zeichen durch Texterkennung
        ausgelesen.}
    \label{fig:pipeline}
\end{figure}

\subsection{Bildsegmentierung}
\label{sec:bildsegmentierung}

Das Ziel einer Bildsegmentierung ist es, die relevanten Bereiche eines
Bildes von den restlichen zu trennen.
In dieser Situation ist es also gefordert, den Bereich des Bildes,
welcher das Nummernschild enth\"alt, vom Rest des Bildes zu trennen.

Zu diesem Zweck kommt in diesem Projekt eine bin\"are Klassifikation
zum Einsatz: F\"ur jeden Pixel des Eingabebildes wird klassifiziert,
ob er Teil des Nummernschildes ist, oder nicht.
Das Ziel ist es also, f\"ur ein Eingabebild eine bin\"are Maske vorherzusagen,
welche f\"ur jeden Pixel eine 1 enth\"alt, falls er Teil des Nummernschildes
ist und anderenfalls eine 0.
Eine visuelle Darstellung dieses Konzeptes ist in
Abbildung~\ref{fig:binaere-maske} gegeben.

\begin{figure}
    \centering
    \begin{subfigure}{0.495\textwidth}
        \centering
        \includegraphics[width=\textwidth]{abbildungen/segmentation_input}
        \caption{Eingabebild}
    \end{subfigure}
    \begin{subfigure}{0.495\textwidth}
        \centering
        \includegraphics[width=\textwidth]{abbildungen/segmentation_output}
        \caption{Bin\"are Maske des Nummernschildes.}
    \end{subfigure}
    \caption{Die bin\"are Maske (rechts) ordnet jedem Pixel der Eingabe
        (links) einen Wert 1 (hier wei{\ss} dargestellt) zu, falls sich dieser
        im Nummernschild befindet. Andernfalls wird ein Wert von 0 (schwarz)
        zugeordnet.}
    \label{fig:binaere-maske}
\end{figure}

Als Klassifikationsverfahren kommen zu diesem Zweck CNNs zum Einsatz,
die bereits in Abschnitt~\ref{sec:cnns} beschrieben wurden.
Auf die genaue Architektur und das Training des Netzes soll nun genauer
eingegangen werden.

Der Ansatz, CNNs zur Bildsegmentierung zu verwenden, geht
auf~\cite{image-segmentation} zur\"uck und wurde hier f\"ur die
vorliegende Problemstellung adaptiert.

\subsubsection{Netzarchitektur}

Wie schon in Abschnitt~\ref{sec:neuronale-netze} erl\"autert, ordnen
neuronale Netze einer Eingabe fester Gr\"o{\ss}e eine zugeh\"orige
Ausgabe fester Gr\"o{\ss}e zu.
In diesem Fall soll die Ausgabe des Netzes zu einem Eingabebild
genau die bin\"are Maske sein, welche das Nummernschild repr\"asentiert.
Da die Bilder im Datensatz allerdings verschiedene Aufl\"osungen
und damit auch verschiedene Gr\"o{\ss}en aufweisen, neuronale Netze
aber auf eine feste einheitliche Gr\"o{\ss}e angewiesen sind,
m\"ussen die Bilder vor der Eingabe in das neuronale Netz
zun\"achst auf eine einheitliche Gr\"o{\ss}e gebracht werden.
In diesem Projekt wird zu diesem Zweck jedes Bild vor der Eingabe
in das Netz auf eine Gr\"o{\ss}e von 400x400 skaliert.

Die komplette Netzarchitektur, die in diesem Projekt zum Einsatz kam,
ist in Abbildung~\ref{fig:netzarchitektur} schematisch dargestellt.
Genaue Details zu jeder Schicht, sowie die Anzahl der trainierbaren
Parameter k\"onnen Tabelle~\ref{tab:netzarchitektur} entnommen werden.

\begin{figure}
    \centering
    \includegraphics[width=\textwidth]{abbildungen/network_architecture}
    \caption{Schematische Darstellung der gew\"ahlten Netzarchitektur
        zur Bildsegmentierung.}
    \label{fig:netzarchitektur}
\end{figure}

\begin{table}
    \centering
    \caption{Die eingesetzte Netzarchitektur. Insgesamt enth\"alt sie
        191297 trainierbare Parameter.}
    \label{tab:netzarchitektur}
    \begin{tabular}{|l|l|l|}
        \hline

        \textbf{Schicht}                       & \textbf{Ausgabegr\"o{\ss}e} & \textbf{Anzahl Parameter} \\

        \hline

        Eingabe                                & 400x400x3                   & 0                         \\

        \hline

        Faltungsschicht, 32 3x3 Kernel, ReLU   & 400x400x32                  & 896                       \\

        \hline

        Max-Pooling, 4x4 Kernel                & 100x100x32                  & 0                         \\

        \hline

        Faltungsschicht, 64 3x3 Kernel, ReLU   & 100x100x64                  & 18496                     \\

        \hline

        Max-Pooling, 4x4 Kernel                & 25x25x64                    & 0                         \\

        \hline

        Faltungsschicht, 128 3x3 Kernel, ReLU  & 25x25x128                   & 73856                     \\

        \hline

        Upsampling                             & 50x50x128                   & 0                         \\

        \hline

        Faltungsschicht, 64 3x3 Kernel, ReLU   & 50x50x64                    & 73792                     \\

        \hline

        Upsampling                             & 100x100x64                  & 0                         \\

        \hline

        Faltungsschicht, 32 3x3 Kernel, ReLU   & 100x100x32                  & 18464                     \\

        \hline

        Upsampling                             & 200x200x32                  & 0                         \\

        \hline

        Faltungsschicht, 16 3x3 Kernel, ReLU   & 200x200x16                  & 4624                      \\

        \hline

        Upsampling                             & 400x400x16                  & 0                         \\

        \hline

        Faltungsschicht, 8 3x3 Kernel, ReLU    & 400x400x8                   & 1160                      \\

        \hline

        Faltungsschicht, 1 3x3 Kernel, Sigmoid & 400x400x1                   & 9                         \\

        \hline
    \end{tabular}
\end{table}

\subsubsection{Training}

Die vorgestellte Netzarchitektur wurde mithilfe der
Programmbibliothek Tensorflow~\cite{tensorflow2015-whitepaper}
implementiert,
das Training wurde auf einer GPU von Google
Colab\footnote{\url{https://colab.research.google.com/}} in der Cloud
durchgef\"uhrt.
Als Optimierungsalgorithmus kam ADAM~\cite{adam},
eine Variante des stochastischen Gradientenabstiegs zum Einsatz.

Vor dem Training wurde der Datensatz durch sogenanntes Data Augmentation
vergr\"o{\ss}ert. Hierbei wurden verschiedene Eigenschaften der
Trainingsbilder zuf\"allig ver\"andert:
\begin{itemize}
    \item Die Bilder wurden horizontal gespiegelt
    \item Aus jedem Bild wurden zuf\"allige Ausschnitte herausgetrennt (random cropping)
    \item Der Kontrast der Bilder wurde zuf\"allig ver\"andert
    \item Die Helligkeit der Bilder wurde zuf\"allig ver\"andert
\end{itemize}
Durch das wiederholte Anwenden dieser Methoden konnte der urspr\"ungliche
Trainingsdatensatz von 949 Bildern auf 22776 Bilder vergr\"o{\ss}ert werden.

Als Validierungsdatensatz, der w\"ahrend des Trainings beobachtet wurde,
um Overfitting zu vermeiden, wurden 20 Bilder per Hand ausgew\"ahlt.
Der Wert der Verlustfunktion w\"ahrend der ersten 15 Epochen des Trainings ist in
Abbildung~\ref{fig:training-loss} zu sehen.
Eine Epoche bedeutet, dass jedes Bild im Datensatz einmal f\"ur einen
Gradientenschritt verwendet wurde.

Als Verlustfunktion wurde hier nicht der in~\ref{sec:training} beschriebene
mittlere quadratische Verlust verwendet, sondern analog zu~\cite{image-segmentation}
die logistische Verlustfunktion (welche auch bei der logistischen Regression zum Einsatz kommt).
Dies hat den Grund, dass diese Verlustfunktion wesentlich besser im
hier vorliegenden Szenario der bin\"aren Klassifikation geeignet ist.

Das Training wurde dann solange durchgef\"uhrt, bis sich der Verlust auf den
20 Validierungsbildern nicht mehr verbessert hat. Man bezeichnet diese
Technik auch als \textbf{early stopping}~\cite{Goodfellow-et-al-2016}.
Das Modell mit dem niedrigsten Validierungs-Verlust wurde dann f\"ur
den weiteren Einsatz in der Pipeline ausgew\"ahlt.

\begin{figure}
    \centering
    \includegraphics[width=0.7\textwidth]{abbildungen/training_plot}
    \caption{Wert der logistischen Verlustfunktion f\"ur Trainings- und Validierungsdatensatz
        innerhalb der ersten 15 Epochen.}
    \label{fig:training-loss}
\end{figure}

\subsubsection{Verarbeitung der Modellvorhersagen}

Um das Modell in der Pipeline einsetzen zu k\"onnen, muss aus den
Modellvorhersagen noch der Bereich extrahiert werden, welcher das
Nummernschild enth\"alt. Die hierzu eingesetzte Vorgehensweise
ist in Abbildung~\ref{fig:verarbeitung} anhand eines Beispielbildes
dargestellt.

\begin{figure}
    \begin{subfigure}{0.495\textwidth}
        \centering
        \includegraphics[width=\textwidth]{abbildungen/verarbeitung_1}
        \caption{Modellvorhersage}
    \end{subfigure}
    \begin{subfigure}{0.495\textwidth}
        \centering
        \includegraphics[width=\textwidth]{abbildungen/verarbeitung_2}
        \caption{Schwellenwert}
    \end{subfigure}
    \begin{subfigure}{0.495\textwidth}
        \centering
        \includegraphics[width=\textwidth]{abbildungen/verarbeitung_3}
        \caption{Umschlie{\ss}endes Rechteck}
    \end{subfigure}
    \begin{subfigure}{0.495\textwidth}
        \centering
        \includegraphics[width=\textwidth]{abbildungen/verarbeitung_4}
        \caption{Ergebnis}
    \end{subfigure}
    \caption{Verarbeitung der Modellvorhersage zur Extraktion des
        Nummernschildes. Das hier gezeigte Bild wurde weder zum Training
        noch zur Validierung w\"ahrend des Trainings verwendet.}
    \label{fig:verarbeitung}
\end{figure}

Der erste Schritt besteht darin, die Vorhersagen des Modells in eine
bin\"are Maske umzuwandeln, welche nur die Werte 1 und 0 enth\"alt
(1 f\"ur Pixel im Nummernschild, 0 f\"ur den Rest).
Da die Ausgabeschicht des eingesetzten Modells aufgrund der
Sigmoid-Funktion Werte im Intervall $[0, 1]$ ausgibt, wird
zu diesem Zweck (analog zur logistischen Regression)
ein Schwellenwertverfahren eingesetzt.
Hat ein Pixel in der Modellvorhersage einen Wert gr\"o{\ss}er als
0,5, so wird dieser in der bin\"aren Maske auf 1 gesetzt, alle
anderen Ausgaben werden auf 0 gesetzt.

Anschlie{\ss}end wird anhand der bin\"aren Maske ein rechteckiger
Ausschnitt bestimmt, in welchem das Nummernschild vermutet wird.
Dies geschieht so, dass zun\"achst f\"ur jeden zusammenh\"angenden
Bereich aus Einsen ein parallel zu den Koordinatenachsen
verlaufendes umschlie{\ss}endes Rechteck bestimmt wird.
Das fl\"achenm\"a{\ss}ig gr\"o{\ss}te dieser Rechtecke wird dann in
der Pipeline zur Extraktion des Nummernschildes verwendet.

Man beachte, dass hier implizit angenommen wird, dass sich
Nummernschilder stets durch ein parallel zur x- und y-Achse
verlaufendes Rechteck beschreiben lassen.
M\"ogliche Probleme mit diesem Ansatz, wie beispielsweise
rotierte Nummernschilder, liegen auf der Hand und werden sp\"ater
in Abschnitt~\ref{sec:ergebnisse} diskutiert.
Dennoch ist ein Vorteil dieses Ansatzes, dass er sehr leicht
umzusetzen ist und trotzdem, wie wir sp\"ater in
Abschnitt~\ref{sec:ergebnisse} sehen werden, zu guten Ergebnissen
f\"uhren kann.

\subsection{Texterkennung}
\label{sec:texterkennung}